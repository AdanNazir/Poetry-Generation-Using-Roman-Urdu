{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2825a6",
   "metadata": {},
   "source": [
    "# Name : Adan Nazir\n",
    "# Email: i191680@nu.edu.pk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b15aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "starting_words=[]# To store the faulty starting words list\n",
    "updated_starting_words=[]# To store the updated words list\n",
    "Alpha_special=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','X','Y','Z','.', ':','’’', \"'\", '\"', '؟','‘','’','‘','%%%%%','٪٪٪٪','!', '%', '`', '\"', ')','‘','‘‘','٪']\n",
    "#special_characters = ['‘','‘‘','٪','٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪٪','%%%%%%%%%%%%%%%%%%%%', '!', '%', '`', '\"', ')', '(',\"''\", '.', ':','’’', \"'\", '\"', '؟','‘','’','‘']#Special characters\n",
    "#which needs to be filtered in the entire text file.\n",
    "words=[] #To store the tokenized words in a list\n",
    "temp=[]\n",
    "\n",
    "def ReadFile():\n",
    "    f = open(\"poetry.txt\", mode='r', encoding='utf-8')# File opened here, encoding is utf-8 since the file contains some special characters.\n",
    "    for line in f:#Traversing through the file in a loop.\n",
    "        line=line.split(\" \")#Split every line into multiple tokens, using spacy was an option as well but I still prefered this method.\n",
    "        starting_words.append(line[0])#Separate the 0th index of every line and store it in the starting words list (faulty)\n",
    "        \n",
    "        for i in range(0,len(line)):#Traverse through the tokenized line list\n",
    "            word=line[i]#extract a single token in each iteration\n",
    "            \n",
    "            #print(word)\n",
    "            if word in Alpha_special:#Check if the token is a special character or not, if yes, then skip it.\n",
    "                continue\n",
    "            words.append(word)#If not a special character, append it into the words list\n",
    "                \n",
    "        line=\"\"#Making the line empty for upcoming traversals.\n",
    "        \n",
    "\n",
    "    for i in range(0,len(starting_words)):#Looping through the faulty starting words\n",
    "        if starting_words[i]=='\\n':#If the starting words contains a new line character, ignore it.\n",
    "            continue\n",
    "        updated_starting_words.append(starting_words[i])#If not a new line, then append it into an updated starting words list.\n",
    "    #print(updated_starting_words)\n",
    "\n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441113c",
   "metadata": {},
   "source": [
    "# Dictionary and its code used from the previous assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07db5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_Dictionary={'a':'ا', 'b':'ب', 'k': 'ک', 'd':'د','f':'ف','g':'گ','h':'ہے','j':'ج','l':'ل','m':'م','n':'ن','p':'پ','q':'ق',\n",
    "               'r':'ر',\n",
    "              's':'س','t':'ت','v':'و','y':'ی','z':'ذ','e':'ے','ha':'ہ','i':'ئ','sh':'ش','ch':'چ','aa':'آ','woh':'وہ','o':'و'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b147edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "English_characters=[]\n",
    "def urdu2roman(text):\n",
    "    English=\"\"\n",
    "    iterations=0\n",
    "    for word in text.split(' '):\n",
    "        temp=list(word)\n",
    "        for character in temp:\n",
    "            English_characters.append(character)\n",
    "            \n",
    "            if character=='ا' and English_characters[0]=='ب':\n",
    "                English+='aa'\n",
    "                \n",
    "            elif character=='ہ' and (English_characters[0]=='و'):\n",
    "                English+='o'\n",
    "                \n",
    "            elif character=='و' and (English_characters[0]=='د' or English_characters[0]=='ت'):\n",
    "                English+='o'\n",
    "                \n",
    "            elif character=='ب' and English_characters[0]=='س':\n",
    "                English+='ab'\n",
    "            \n",
    "            elif character=='ی' and (English_characters[0]=='ک' or English_characters[0]=='ج'):\n",
    "                English+='ai'\n",
    "                \n",
    "            elif character=='و' and (English_characters[iterations-1]=='ہ' or English_characters[iterations-1]=='ل'):\n",
    "                English+='o'\n",
    "                \n",
    "            elif character=='ی' and (English_characters[iterations-1]=='ف' or English_characters[iterations-1]=='م'):\n",
    "            \n",
    "                English+='i'\n",
    "                \n",
    "            elif character=='ی' and English_characters[0]=='ب':\n",
    "\n",
    "                English+='e'\n",
    "                \n",
    "            elif character=='ی' and English_characters[0]=='ٹ':\n",
    "                English+='ea'\n",
    "                \n",
    "            elif character=='ہ' and English_characters[0]=='ک':\n",
    "                English+='e'\n",
    "                    \n",
    "            elif character=='ہ' and English_characters[0]=='ن':\n",
    "                English+='a'\n",
    "                \n",
    "            elif character=='ی' and English_characters[iterations]=='ہ':\n",
    "                English+='hi'\n",
    "                \n",
    "            elif character=='ظ' and English_characters[0]=='ن':\n",
    "                English+='aza'\n",
    "                \n",
    "            elif character=='ہ' and English_characters[0]=='س':\n",
    "                \n",
    "                English+='eh'\n",
    "            \n",
    "            elif character=='د' and English_characters[0]=='ب':\n",
    "                English+='ad'\n",
    "                \n",
    "            elif character=='ز':\n",
    "                English+='z'\n",
    "                \n",
    "                \n",
    "                \n",
    "            elif character=='ں':\n",
    "                English+='n'\n",
    "                    \n",
    "            elif character=='ع':\n",
    "                English+='a'\n",
    "                \n",
    "            elif character=='ر' and English_characters[0]=='ک':\n",
    "                English+='ar'\n",
    "                \n",
    "            elif character=='ڑ':\n",
    "                English+='ar'\n",
    "                \n",
    "            elif character=='ھ':\n",
    "                English+='h'\n",
    "                \n",
    "            elif character=='د':\n",
    "                English+='d'\n",
    "            \n",
    "            elif character=='آ':\n",
    "                English+='a'\n",
    "            \n",
    "            elif character=='ٹ':\n",
    "                English+='t'\n",
    "            \n",
    "            elif character=='خ':\n",
    "                English+='kh'\n",
    "                \n",
    "            elif character=='د' and English_characters[0]=='خ':\n",
    "                English+='ud'\n",
    "                \n",
    "                        \n",
    "                \n",
    "            else:\n",
    "                    \n",
    "                for english,urdu in My_Dictionary.items():\n",
    "                    if character==urdu:\n",
    "                        English+=english\n",
    "                        \n",
    "                        \n",
    "            iterations+=1\n",
    "        iterations=0\n",
    "        English_characters.clear()\n",
    "                \n",
    "                \n",
    "        \n",
    "        English+=' '\n",
    "        \n",
    "    \n",
    "    print(English)\n",
    "    print(\"\\n\")\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0a35d",
   "metadata": {},
   "source": [
    "# Bigram Model coded here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a343b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bigram_Probability(start_word):#Function defined for calculating Bigram Probability here\n",
    "    words_freq=0 #Initially, the frequency of the upcoming starting word will be kept as zero\n",
    "    recurring=[]#To check if the next word coming after the starting word has already been traversed before or not.\n",
    "    words_list=[]\n",
    "    probability=0#Initial probability is kept as zero\n",
    "    probabilities=[]#To store the probability of each succeeding word after the starting word in a probabilities list\n",
    "    \n",
    "    words_freq=words.count(start_word)#Calculating the no of occurences of the starting word in the entire words list.\n",
    "        \n",
    "    \n",
    "    for i in range(0,len(words)-1):#Traversing through the entire words list. It will traverse through n-1 times in order to \n",
    "        #avoid run time list out of range error.\n",
    "        if words[i]==start_word:# If the starting word is found in the entire words list, go down.\n",
    "            next_word=words[i+1]#Extract the succeeding word after the starting word\n",
    "            if next_word not in recurring:# If the next word hasn't been traversed on before, pass\n",
    "                recurring.append(next_word)#Append the next word in the recurring word so that it can be skipped if it comes\n",
    "                #in the loop again\n",
    "                for j in range(0,len(words)-1):#If it isn't a recurring word, traverse through the words list again\n",
    "                    if j+1<len(words):#If the next coming word's index is less than the total words list, pass\n",
    "                        if words[j]==start_word and words[j+1]==next_word: # If current word is a start word and its next iteration is a next word\n",
    "                            probability+=1 #Increment the frequency/probability by 1\n",
    "                 \n",
    "                    if probability>0:#If the probability of a bigram is greater than 0, pass\n",
    "                        p=probability/words_freq #Calculate the bigram's probability\n",
    "                        probabilities.append(p) #Append its probability into a probabilites list\n",
    "                        probability=0 #Reset the counter\n",
    "                        word=next_word #Catch the next word\n",
    "                        words_list.append(word)#Append the next word into a new words list\n",
    "\n",
    "    max_prob=max(probabilities)#Extract the max probability of the word from the entire list\n",
    "    max_index=probabilities.index(max_prob)#Fetch the index of the most probable word\n",
    "    return words_list[max_index]#Return the most probable next word\n",
    "    \n",
    "\n",
    "def GeneratePoetryUsingBigram():\n",
    "    verse=\"\"\n",
    "    start=random.choice(updated_starting_words)#Grabbing a random word from the entire collection of starting words.\n",
    "    verse+=start#Concatenating it to the verse string\n",
    "    next_word=Bigram_Probability(start)#Sending the starting word to the Bigram mode;\n",
    "    verse+=' '+next_word#Appending the returned value to the verse string\n",
    "    counts=0\n",
    "    \n",
    "    ran_count=random.randint(6,8)#Generating a random range of words in each verse for the poetry\n",
    "    for i in range(1):#Creating 6 rows \n",
    "        for j in range(7):#Creating 6 columns\n",
    "            for k in range(ran_count):#Creating a verse with randomly returned number of words.\n",
    "                next_word=Bigram_Probability(next_word)#Sending the next word to the model\n",
    "                verse+=' '+next_word#Appending its value to the verse string\n",
    "                counts+=1#Incrementing count by 1 just to check if the no.of words in the verse have been concatenated or not\n",
    "                if counts==ran_count:#If the number of words are equal to the random no of words for each verse:\n",
    "                    if len(verse)>2:#If the number of words in the newly generated verse are more than 2:\n",
    "                        #print(verse)\n",
    "                        urdu2roman(verse)#Print it\n",
    "                        verse=\" \"#Empty it\n",
    "                        next_word = random.choice(updated_starting_words)#Pick another starting word\n",
    "                        verse = verse + next_word#Same as above\n",
    "                        verse_count = random.randint(6,8) #Same as above       \n",
    "                        counts = 1#Reset the count \n",
    "                        break#Break this loop.\n",
    "                    \n",
    "                    else:#If the number of words in the verse are less than 2:\n",
    "                        counts=1#Again, reset the counter\n",
    "                        verse=\"\"#Empty the verse\n",
    "                        next_word = random.choice(updated_starting_words)#Same as above\n",
    "                        verse = verse + next_word#Same as above\n",
    "                        verse_count = random.randint(6,8) #Same as above\n",
    "                        break#Same as above, break the loop.\n",
    "                \n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15a9d7",
   "metadata": {},
   "source": [
    "# Trigram model coded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0de3eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trigram_Probability(start_word):#Same as the Bigram model but with a few tweaks.\n",
    "    words_freq=0\n",
    "    recurring=[]\n",
    "    next_recurring=[]\n",
    "    words_list=[]\n",
    "    probability=0\n",
    "    probabilities=[]\n",
    "    words_freq=words.count(start_word)\n",
    "    \n",
    "        \n",
    "    \n",
    "    for i in range(0,len(words)-1):\n",
    "        if words[i]==start_word:\n",
    "            next_word=words[i+1]\n",
    "            if next_word not in recurring:\n",
    "                recurring.append(next_word)\n",
    "                second_nextword=words[i+2]#Here, once we extract the starting and the next non recurring word, we then extract the next most frequent word\n",
    "                if second_nextword not in next_recurring:#We check if the third most frequent word has been traversed on before or not.\n",
    "                    next_recurring.append(second_nextword)#If not, append it to the recurring list\n",
    "                    for j in range(0,len(words)-1):\n",
    "                        if j+2<len(words):\n",
    "                            if words[j]==start_word and words[j+1]==next_word and words[j+2]==second_nextword:#Same condition as in the Bigram model but here it will check every 2 successful words after each starting word:\n",
    "                                probability+=1#If found, increment the probability\n",
    "                 \n",
    "                        if probability>0:#Same as the Bigram model.\n",
    "                            p=probability/words_freq\n",
    "                            probabilities.append(p)\n",
    "                            probability=0\n",
    "                            word=next_word\n",
    "                            words_list.append(word)\n",
    "                        \n",
    "                    \n",
    "    max_prob=max(probabilities)\n",
    "    max_index=probabilities.index(max_prob)\n",
    "    return words_list[max_index]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "622de3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratePoetryUsingTrigram():#Same as the Bigram model.\n",
    "    verse=\"\"\n",
    "    start=random.choice(updated_starting_words)\n",
    "    verse+=start\n",
    "    next_word=Bigram_Probability(start)\n",
    "    verse+=' '+next_word\n",
    "    counts=0\n",
    "    \n",
    "    ran_count=random.randint(6,8)\n",
    "    for i in range(1):\n",
    "        for j in range(7):\n",
    "            for k in range(ran_count):\n",
    "                next_word=Bigram_Probability(next_word)\n",
    "                verse+=' '+next_word\n",
    "                counts+=1\n",
    "                if counts==ran_count:\n",
    "                    if len(verse)>2:\n",
    "                        #print(verse)\n",
    "                        urdu2roman(verse)\n",
    "                        verse=\" \"\n",
    "                        next_word = random.choice(updated_starting_words)\n",
    "                        verse = verse + next_word\n",
    "                        verse_count = random.randint(6,8)        \n",
    "                        counts = 1\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        counts=1\n",
    "                        verse=\"\"\n",
    "                        next_word = random.choice(updated_starting_words)\n",
    "                        verse = verse + next_word\n",
    "                        verse_count = random.randint(6,8) \n",
    "                        break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65d6cc",
   "metadata": {},
   "source": [
    "# Backward Model coded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f7215f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackwardProbability(start_word):#Same as the Bigram model but with a single tweak\n",
    "    words_freq=0\n",
    "    freq_count=[]\n",
    "    test=0\n",
    "    recurring=[]\n",
    "    words_list=[]\n",
    "    probability=0\n",
    "    probabilities=[]\n",
    "    temp=\"\"\n",
    "    words_freq=words.count(start_word)\n",
    "        \n",
    "    \n",
    "    for i in range(0,len(words)-1):\n",
    "        if words[i]==start_word:\n",
    "            prev_word=words[i-1]#Here, once the starting word is found in the list, we then extract the previous word.\n",
    "            if prev_word not in recurring:\n",
    "                recurring.append(prev_word)\n",
    "                for j in range(0,len(words)-1):\n",
    "                    if j+1<len(words):\n",
    "                        if words[j]==start_word and words[j-1]==prev_word:#Here we check if the current word is a start word and its previous index is the previous word\n",
    "                            probability+=1\n",
    "                 \n",
    "                    if probability>0:#Same as the Bigram model\n",
    "                        p=probability/words_freq\n",
    "                        probabilities.append(p)\n",
    "                        probability=0\n",
    "                        word=prev_word\n",
    "                        words_list.append(word)\n",
    "\n",
    "    max_prob=max(probabilities)\n",
    "    max_index=probabilities.index(max_prob)\n",
    "    return words_list[max_index]\n",
    "    \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd2618e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratePoetryUsingBackward():#Same as the Bigram model.\n",
    "    verse=\"\"\n",
    "    start=random.choice(updated_starting_words)\n",
    "    verse+=start\n",
    "    next_word=Bigram_Probability(start)\n",
    "    verse+=' '+next_word\n",
    "    counts=0\n",
    "    \n",
    "    ran_count=random.randint(6,8)\n",
    "    for i in range(1):\n",
    "        for j in range(7):\n",
    "            for k in range(7):\n",
    "                next_word=Bigram_Probability(next_word)\n",
    "                verse+=' '+next_word\n",
    "                counts+=1\n",
    "                if counts==ran_count:\n",
    "                    if len(verse)>2:\n",
    "                        #urdu2roman(verse)\n",
    "                        #print(verse)\n",
    "                        urdu2roman(verse)\n",
    "                        verse=\" \"\n",
    "                        next_word = random.choice(updated_starting_words)\n",
    "                        verse = verse + next_word\n",
    "                        verse_count = random.randint(6,8)        \n",
    "                        counts = 1\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        counts=1\n",
    "                        verse=\"\"\n",
    "                        next_word = random.choice(updated_starting_words)\n",
    "                        verse = verse + next_word\n",
    "                        verse_count = random.randint(6,8) \n",
    "                        break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c0c2c",
   "metadata": {},
   "source": [
    "# ReadFile and Poetry generation functions to be called below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acaaa172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yha dl ryb sehy tmhaare nam pha aiyn ge \n",
      "\n",
      "\n",
      " droysh kai lb grha min rng bhre \n",
      "\n",
      "\n",
      " talyf nskha haaie vofa  qfs adas \n",
      "\n",
      "\n",
      " voo be nqab aie as ke gryban \n",
      "\n",
      "\n",
      " bhat kchh to keo keain to keo \n",
      "\n",
      "\n",
      " haoie mday ke gryban ka kaarvobaar chle \n",
      "\n",
      "\n",
      " fi kvoiai raha min rng bhre baaad \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ReadFile()\n",
    "GeneratePoetryUsingBigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751146dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
